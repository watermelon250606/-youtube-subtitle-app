from flask import Flask, request, jsonify, render_template_string
from flask_cors import CORS
import subprocess
import os
import re
import tempfile
import json
from collections import OrderedDict
import requests

app = Flask(__name__)
CORS(app, origins=['*'])  # ëª¨ë“  ì˜¤ë¦¬ì§„ í—ˆìš©

# ì¶”ê°€ CORS í—¤ë” ì„¤ì •
@app.after_request
def after_request(response):
    response.headers.add('Access-Control-Allow-Origin', '*')
    response.headers.add('Access-Control-Allow-Headers', 'Content-Type,Authorization')
    response.headers.add('Access-Control-Allow-Methods', 'GET,PUT,POST,DELETE,OPTIONS')
    return response

def extract_video_id(url):
    """YouTube URLì—ì„œ ë¹„ë””ì˜¤ ID ì¶”ì¶œ"""
    regex = r'(?:v=|\/|youtu\.be\/)([0-9A-Za-z_-]{11})'
    match = re.search(regex, url)
    return match.group(1) if match else None

def extract_text_from_vtt(vtt_content):
    """VTT íŒŒì¼ì—ì„œ ê°•ë ¥í•œ ì¤‘ë³µ ì œê±°í•˜ë©° í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    lines = vtt_content.split('\n')
    raw_segments = []
    
    # 1ë‹¨ê³„: VTTì—ì„œ ìˆœìˆ˜ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ
    for line in lines:
        line = line.strip()
        
        # VTT í—¤ë”, ì‹œê°„ ì •ë³´, ë¹ˆ ì¤„ ê±´ë„ˆë›°ê¸°
        if (not line or 
            line.startswith('WEBVTT') or 
            '-->' in line or 
            line.isdigit() or
            'Kind:' in line or
            'Language:' in line or
            line.startswith('NOTE') or
            line.startswith('<') or
            re.match(r'^\d+$', line)):
            continue
            
        # HTML íƒœê·¸ ì œê±°
        clean_line = re.sub(r'<[^>]+>', '', line)
        clean_line = clean_line.strip()
        
        if clean_line and len(clean_line) > 3:
            raw_segments.append(clean_line)
    
    # 2ë‹¨ê³„: ê°•ë ¥í•œ ì¤‘ë³µ ì œê±°
    cleaned_segments = remove_all_duplicates(raw_segments)
    
    # 3ë‹¨ê³„: ìµœì¢… í…ìŠ¤íŠ¸ ì¡°í•©
    return ' '.join(cleaned_segments)

def remove_all_duplicates(segments):
    """ëª¨ë“  ì¢…ë¥˜ì˜ ì¤‘ë³µì„ ì œê±°í•˜ëŠ” ê°•ë ¥í•œ í•¨ìˆ˜"""
    if not segments:
        return []
    
    # 1ë‹¨ê³„: ì™„ì „íˆ ë™ì¼í•œ ì—°ì† ì„¸ê·¸ë¨¼íŠ¸ ì œê±°
    no_consecutive = []
    prev_segment = ""
    
    for segment in segments:
        if segment != prev_segment:
            no_consecutive.append(segment)
            prev_segment = segment
    
    # 2ë‹¨ê³„: ìœ ì‚¬ë„ ê¸°ë°˜ ì¤‘ë³µ ì œê±° (ë” ì—„ê²©í•˜ê²Œ)
    final_segments = []
    
    for segment in no_consecutive:
        is_duplicate = False
        
        # ì´ë¯¸ ì¶”ê°€ëœ ì„¸ê·¸ë¨¼íŠ¸ë“¤ê³¼ ë¹„êµ
        for existing in final_segments:
            similarity = calculate_advanced_similarity(segment, existing)
            if similarity > 0.75:  # 75% ì´ìƒ ìœ ì‚¬í•˜ë©´ ì¤‘ë³µìœ¼ë¡œ ê°„ì£¼
                is_duplicate = True
                break
        
        if not is_duplicate:
            final_segments.append(segment)
    
    # 3ë‹¨ê³„: ì—°ì† ë°˜ë³µ íŒ¨í„´ ì œê±°
    return remove_repetitive_patterns(final_segments)

def calculate_advanced_similarity(text1, text2):
    """ê³ ê¸‰ ìœ ì‚¬ë„ ê³„ì‚° (ë‹¨ì–´ ê¸°ë°˜ + ê¸¸ì´ ê³ ë ¤)"""
    if not text1 or not text2:
        return 0.0
    
    # ë‹¨ì–´ ë¶„í• 
    words1 = set(text1.lower().split())
    words2 = set(text2.lower().split())
    
    if not words1 or not words2:
        return 0.0
    
    # ìì¹´ë“œ ìœ ì‚¬ë„ ê³„ì‚°
    intersection = len(words1.intersection(words2))
    union = len(words1.union(words2))
    jaccard = intersection / union if union > 0 else 0.0
    
    # ê¸¸ì´ ìœ ì‚¬ë„ ê³ ë ¤
    len_ratio = min(len(text1), len(text2)) / max(len(text1), len(text2))
    
    # ìµœì¢… ìœ ì‚¬ë„ (ìì¹´ë“œ ìœ ì‚¬ë„ 70% + ê¸¸ì´ ìœ ì‚¬ë„ 30%)
    return jaccard * 0.7 + len_ratio * 0.3

def remove_repetitive_patterns(segments):
    """ë°˜ë³µ íŒ¨í„´ ì œê±° (ì˜ˆ: A B A B A B -> A B)"""
    if len(segments) < 4:
        return segments
    
    result = []
    i = 0
    
    while i < len(segments):
        current_segment = segments[i]
        
        # íŒ¨í„´ ê¸¸ì´ 1-3ê¹Œì§€ í™•ì¸
        pattern_found = False
        
        for pattern_length in range(1, min(4, len(segments) - i)):
            # í˜„ì¬ ìœ„ì¹˜ì—ì„œ íŒ¨í„´ ì¶”ì¶œ
            pattern = segments[i:i + pattern_length]
            
            # íŒ¨í„´ì´ ì–¼ë§ˆë‚˜ ë°˜ë³µë˜ëŠ”ì§€ í™•ì¸
            repeat_count = 0
            j = i
            
            while j + pattern_length <= len(segments):
                if segments[j:j + pattern_length] == pattern:
                    repeat_count += 1
                    j += pattern_length
                else:
                    break
            
            # 3ë²ˆ ì´ìƒ ë°˜ë³µë˜ë©´ íŒ¨í„´ìœ¼ë¡œ ê°„ì£¼
            if repeat_count >= 3:
                result.extend(pattern)
                i = j
                pattern_found = True
                break
        
        if not pattern_found:
            result.append(current_segment)
            i += 1
    
    return result

def advanced_clean_subtitle(raw_text):
    """ê³ ê¸‰ ìë§‰ ì •ë¦¬ í•¨ìˆ˜ - ì¤‘ë³µ ì œê±° í¬í•¨"""
    
    # 1. HTML íƒœê·¸ì™€ ì‹œê°„ ì •ë³´ ì œê±°
    cleaned = re.sub(r'<[^>]+>', '', raw_text)
    cleaned = re.sub(r'\[ìŒì•…\]', 'â™ª', cleaned)
    
    # 2. ì—°ì†ëœ ê³µë°±ì„ í•˜ë‚˜ë¡œ
    cleaned = re.sub(r'\s+', ' ', cleaned)
    cleaned = cleaned.strip()
    
    # 3. ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„í• 
    sentences = re.split(r'[.!?ã€‚]', cleaned)
    
    # 4. ì¤‘ë³µ ì œê±°ë¥¼ ìœ„í•œ OrderedDict ì‚¬ìš©
    unique_sentences = OrderedDict()
    
    for sentence in sentences:
        sentence = sentence.strip()
        
        # ë„ˆë¬´ ì§§ì€ ì¡°ê° ì œê±°
        if len(sentence) < 10:
            continue
        
        # ì˜ë¯¸ìˆëŠ” ë¬¸ì¥ë§Œ ì¶”ê°€
        if is_meaningful_sentence(sentence):
            # ì¤‘ë³µ ì²´í¬ (ìœ ì‚¬í•œ ë¬¸ì¥ ì œê±°)
            if not is_duplicate_sentence(sentence, unique_sentences):
                unique_sentences[sentence] = True
    
    # 5. ìµœì¢… í…ìŠ¤íŠ¸ ìƒì„±
    final_sentences = []
    for sentence in unique_sentences.keys():
        final_sentences.append(sentence.strip() + '.')
    
    return '\n\n'.join(final_sentences)

def is_meaningful_sentence(sentence):
    """ì˜ë¯¸ìˆëŠ” ë¬¸ì¥ì¸ì§€ íŒë‹¨"""
    # ë‹¨ìˆœ ë°˜ë³µì´ë‚˜ ì˜ë¯¸ì—†ëŠ” ë‹¨ì–´ë“¤ ì œê±°
    meaningless_patterns = [
        r'^(ë„¤|ì•„|ì–´|ìŒ|ê·¸|ì´|ì €|ìš”|í•´|í• |ëœ|ë˜|ìˆ˜|ê²ƒ|ê±¸|ë¥¼|ì„|ì´|ê°€|ì˜|ì—|ë¡œ|ìœ¼ë¡œ|ì™€|ê³¼|ë„|ë§Œ|ë¶€í„°|ê¹Œì§€|ì—ì„œ|ì—ê²Œ|í•œí…Œ|ë³´ë‹¤|ì²˜ëŸ¼|ê°™ì´|ë§ˆë‹¤|ë§ˆì €|ì¡°ì°¨|ë¼ë„|ë“ ì§€|ê±°ë‚˜)\s*$',
        r'^[ã„±-ã…ã…-ã…£]+$',  # ììŒ, ëª¨ìŒë§Œ
        r'^\s*$',  # ê³µë°±ë§Œ
    ]
    
    for pattern in meaningless_patterns:
        if re.match(pattern, sentence):
            return False
    
    return True

def is_duplicate_sentence(new_sentence, existing_sentences):
    """ì¤‘ë³µ ë¬¸ì¥ì¸ì§€ í™•ì¸ (ìœ ì‚¬ë„ ê¸°ë°˜)"""
    for existing in existing_sentences.keys():
        # ì™„ì „íˆ ê°™ì€ ê²½ìš°
        if new_sentence == existing:
            return True
        
        # ìœ ì‚¬ë„ ì²´í¬
        similarity = calculate_text_similarity(new_sentence, existing)
        if similarity > 0.8:  # 80% ì´ìƒ ìœ ì‚¬í•˜ë©´ ì¤‘ë³µìœ¼ë¡œ ê°„ì£¼
            return True
    
    return False

def calculate_text_similarity(text1, text2):
    """ë‘ í…ìŠ¤íŠ¸ì˜ ìœ ì‚¬ë„ ê³„ì‚° (ê°œì„ ëœ ë²„ì „)"""
    if not text1 or not text2:
        return 0
    
    # ê¸¸ì´ê°€ ë„ˆë¬´ ë‹¤ë¥´ë©´ ìœ ì‚¬ë„ ë‚®ìŒ
    len_ratio = min(len(text1), len(text2)) / max(len(text1), len(text2))
    if len_ratio < 0.5:
        return 0
    
    # ë‹¨ì–´ ë‹¨ìœ„ë¡œ ë¹„êµ
    words1 = set(text1.split())
    words2 = set(text2.split())
    
    if not words1 or not words2:
        return 0
    
    # êµì§‘í•©ê³¼ í•©ì§‘í•©ìœ¼ë¡œ ìœ ì‚¬ë„ ê³„ì‚°
    intersection = len(words1.intersection(words2))
    union = len(words1.union(words2))
    
    return intersection / union if union > 0 else 0

@app.route('/')
def index():
    """ë©”ì¸ í˜ì´ì§€"""
    with open('youtube_subtitle_extractor.html', 'r', encoding='utf-8') as f:
        html_content = f.read()
    return html_content

@app.route('/manifest.json')
def manifest():
    """PWA ë§¤ë‹ˆí˜ìŠ¤íŠ¸ íŒŒì¼"""
    with open('manifest.json', 'r', encoding='utf-8') as f:
        manifest_content = f.read()
    response = app.response_class(
        response=manifest_content,
        status=200,
        mimetype='application/json'
    )
    return response

@app.route('/sw.js')
def service_worker():
    """Service Worker íŒŒì¼"""
    with open('sw.js', 'r', encoding='utf-8') as f:
        sw_content = f.read()
    response = app.response_class(
        response=sw_content,
        status=200,
        mimetype='application/javascript'
    )
    return response

@app.route('/extract', methods=['POST', 'OPTIONS'])
def extract_subtitle():
    """ìë§‰ ì¶”ì¶œ API"""
    # OPTIONS ìš”ì²­ ì²˜ë¦¬ (CORS preflight)
    if request.method == 'OPTIONS':
        response = app.make_default_options_response()
        headers = response.headers
        headers['Access-Control-Allow-Origin'] = '*'
        headers['Access-Control-Allow-Methods'] = 'POST, OPTIONS'
        headers['Access-Control-Allow-Headers'] = 'Content-Type'
        return response
    
    try:
        data = request.get_json()
        url = data.get('url', '').strip()
        
        if not url:
            return jsonify({'error': 'URLì´ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'}), 400
        
        # ë¹„ë””ì˜¤ ID ì¶”ì¶œ
        video_id = extract_video_id(url)
        if not video_id:
            return jsonify({'error': 'ì˜¬ë°”ë¥¸ YouTube URLì´ ì•„ë‹™ë‹ˆë‹¤.'}), 400
        
        # yt-dlp ì„¤ì¹˜ í™•ì¸
        try:
            subprocess.run(['yt-dlp', '--version'], 
                         capture_output=True, text=True, shell=True, check=True)
        except subprocess.CalledProcessError:
            return jsonify({'error': 'yt-dlpê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install yt-dlpë¡œ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.'}), 500
        
        # ì„ì‹œ ë””ë ‰í† ë¦¬ ìƒì„±
        with tempfile.TemporaryDirectory() as temp_dir:
            # ìë§‰ ë‹¤ìš´ë¡œë“œ ëª…ë ¹
            cmd = [
                'yt-dlp',
                '--write-subs',
                '--write-auto-subs',
                '--sub-langs', 'ko,en',
                '--skip-download',
                '--sub-format', 'vtt',
                '-o', os.path.join(temp_dir, 'subtitle_%(id)s.%(ext)s'),
                url
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True, shell=True)
            
            if result.returncode != 0:
                return jsonify({'error': f'ìë§‰ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {result.stderr}'}), 500
            
            # ë‹¤ìš´ë¡œë“œëœ ìë§‰ íŒŒì¼ ì°¾ê¸°
            possible_files = [
                os.path.join(temp_dir, f'subtitle_{video_id}.ko.vtt'),
                os.path.join(temp_dir, f'subtitle_{video_id}.en.vtt'),
                os.path.join(temp_dir, f'subtitle_{video_id}.vtt')
            ]
            
            subtitle_content = None
            language = None
            
            for filename in possible_files:
                if os.path.exists(filename):
                    with open(filename, 'r', encoding='utf-8') as f:
                        content = f.read()
                    
                    # VTTì—ì„œ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ - ê°œì„ ëœ ë°©ì‹
                    subtitle_content = extract_text_from_vtt(content)
                    
                    # ì–¸ì–´ íŒë³„
                    if '.ko.' in filename:
                        language = 'í•œêµ­ì–´ (ìë™ ìƒì„±) - ì¤‘ë³µ ì œê±°ë¨'
                    elif '.en.' in filename:
                        language = 'ì˜ì–´ (ìë™ ìƒì„±) - ì¤‘ë³µ ì œê±°ë¨'
                    else:
                        language = 'ìë™ ìƒì„± - ì¤‘ë³µ ì œê±°ë¨'
                    
                    break
            
            if not subtitle_content:
                return jsonify({'error': 'ì‚¬ìš© ê°€ëŠ¥í•œ ìë§‰ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}), 404
            
            # ê³ ê¸‰ í…ìŠ¤íŠ¸ ì •ë¦¬ (ì¤‘ë³µ ì œê±° í¬í•¨)
            cleaned_text = advanced_clean_subtitle(subtitle_content)
            
            return jsonify({
                'success': True,
                'video_id': video_id,
                'subtitle': cleaned_text,
                'language': language,
                'length': len(cleaned_text)
            })
            
    except Exception as e:
        return jsonify({'error': f'ì„œë²„ ì˜¤ë¥˜: {str(e)}'}), 500

if __name__ == '__main__':
    print("ğŸ¬ YouTube ìë§‰ ì¶”ì¶œê¸° ì„œë²„ ì‹œì‘! (ì¤‘ë³µ ì œê±° ê¸°ëŠ¥ í¬í•¨)")
    print("ğŸ“± ë¸Œë¼ìš°ì €ì—ì„œ http://localhost:5000 ì„ ì—´ì–´ì£¼ì„¸ìš”!")
    print("=" * 50)
    app.run(debug=True, host='0.0.0.0', port=5000)  # ëª¨ë“  ì¸í„°í˜ì´ìŠ¤ì—ì„œ ì ‘ê·¼ ê°€ëŠ¥

# Vercelì„ ìœ„í•œ WSGI app export
application = app 